{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e82314c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pmdarima as pm\\nimport os\\nimport pandas as pd\\n\\nclean_path = os.path.join(\"..\", \"data\", \"processed\")\\ntickers = [ticker for ticker in os.listdir(clean_path) if ticker.endswith(\\'.csv\\')]\\nforecast_results = {}\\n\\n# Forecasting next n days for each ticker\\nfor ticker in tickers:\\n    file_path = os.path.join(clean_path, ticker)\\n    cols = pd.read_csv(file_path, nrows=0).columns\\n    if ticker == \"import_data.csv\":\\n        continue\\n    data = pd.read_csv(file_path, parse_dates=[\"Date\"], index_col=\"Date\", low_memory=False)\\n    data = data.asfreq(\\'B\\').ffill()\\n    returns = data[\"Return\"].dropna()\\n    model = pm.auto_arima(returns, start_p=0, d=None, start_q=0, max_p=3, max_q=3, seasonal=False, stepwise=True, suppress_warnings=True, n_jobs=1)\\n    forecast_vals = model.predict(steps=10)\\n    forecast_i = pd.bdate_range(start=returns.index[-1] + pd.offsets.BDay(1), periods=10, freq=\\'B\\')\\n    forecast = pd.Series(forecast_vals, index=forecast_i)\\n    forecast_results[ticker] = forecast\\n    print(\"finished!\")\\nprint(forecast_results)\\n\\n# Saving the forecast results to a CSV file \\nforecast_df = pd.DataFrame(forecast_results)\\noutput_path = os.path.join(\"..\", \"data\", \"forecasts\", \"forecasted_returns.csv\")\\nforecast_df.to_csv(output_path)  \\n    \\n# Getting the diagram for how it looks\\n# Printing a prediction for whether or not its a good idea to invest or not\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pmdarima as pm\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "clean_path = os.path.join(\"..\", \"data\", \"processed\")\n",
    "tickers = [ticker for ticker in os.listdir(clean_path) if ticker.endswith('.csv')]\n",
    "forecast_results = {}\n",
    "\n",
    "# Forecasting next n days for each ticker\n",
    "for ticker in tickers:\n",
    "    file_path = os.path.join(clean_path, ticker)\n",
    "    cols = pd.read_csv(file_path, nrows=0).columns\n",
    "    if ticker == \"import_data.csv\":\n",
    "        continue\n",
    "    data = pd.read_csv(file_path, parse_dates=[\"Date\"], index_col=\"Date\", low_memory=False)\n",
    "    data = data.asfreq('B').ffill()\n",
    "    returns = data[\"Return\"].dropna()\n",
    "    model = pm.auto_arima(returns, start_p=0, d=None, start_q=0, max_p=3, max_q=3, seasonal=False, stepwise=True, suppress_warnings=True, n_jobs=1)\n",
    "    forecast_vals = model.predict(steps=10)\n",
    "    forecast_i = pd.bdate_range(start=returns.index[-1] + pd.offsets.BDay(1), periods=10, freq='B')\n",
    "    forecast = pd.Series(forecast_vals, index=forecast_i)\n",
    "    forecast_results[ticker] = forecast\n",
    "    print(\"finished!\")\n",
    "print(forecast_results)\n",
    "\n",
    "# Saving the forecast results to a CSV file \n",
    "forecast_df = pd.DataFrame(forecast_results)\n",
    "output_path = os.path.join(\"..\", \"data\", \"forecasts\", \"forecasted_returns.csv\")\n",
    "forecast_df.to_csv(output_path)  \n",
    "    \n",
    "# Getting the diagram for how it looks\n",
    "# Printing a prediction for whether or not its a good idea to invest or not\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d30e51f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use matplotlib to plot the results on a graph to be used in the dashboard\n",
    "## on dashboard when user selects a ticker, show the graph of the returns and the forecast\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccb9f3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, numpy as np, pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pmdarima as pm\n",
    "\n",
    "DATA = \"../data/processed\"              # your existing cleaned files\n",
    "ART  = \"../artifacts/forecasts\"         # where we’ll save outputs\n",
    "os.makedirs(ART, exist_ok=True)\n",
    "\n",
    "H = 10                                  # forecast horizon (business days)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b49e074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_returns_and_price(ticker: str):\n",
    "    \"\"\"Load Return + last Close; enforce BDay index; forward-fill gaps.\"\"\"\n",
    "    df = pd.read_csv(os.path.join(DATA, f\"{ticker}.csv\"),\n",
    "                     parse_dates=[\"Date\"], index_col=\"Date\", low_memory=False)\n",
    "    df = df.sort_index()\n",
    "    s = df[\"Return\"].asfreq(\"B\").ffill().dropna()\n",
    "    p0 = df[\"Close\"].iloc[-1]\n",
    "    return s, float(p0)\n",
    "\n",
    "def arima_mean_path(returns: pd.Series, h: int = H) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Fast baseline: ARIMA(1,0,1) on returns (stationary). \n",
    "    If anything fails, fall back to zeros (μ≈0).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Statsmodels-style ARIMA through pmdarima’s wrapper (fast)\n",
    "        model = pm.ARIMA(order=(1,0,1)).fit(returns.values)\n",
    "        mu = model.predict(n_periods=h)  # point forecasts of daily returns\n",
    "    except Exception:\n",
    "        mu = np.zeros(h)\n",
    "\n",
    "    idx = pd.bdate_range(returns.index[-1] + pd.offsets.BDay(1), periods=h)\n",
    "    return pd.Series(mu, index=idx)\n",
    "\n",
    "def list_tickers():\n",
    "    return sorted([f[:-4] for f in os.listdir(DATA) if f.endswith(\".csv\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "831664cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting:   0%|                                      | 0/109 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Close'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\lowsl\\New folder\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Close'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m last_close \u001b[38;5;241m=\u001b[39m {}   \u001b[38;5;66;03m# {ticker: float}\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tqdm(tickers, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForecasting\u001b[39m\u001b[38;5;124m\"\u001b[39m, ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     r, p0 \u001b[38;5;241m=\u001b[39m load_returns_and_price(t)\n\u001b[0;32m      7\u001b[0m     mu \u001b[38;5;241m=\u001b[39m arima_mean_path(r, H)\n\u001b[0;32m      8\u001b[0m     mean_paths[t] \u001b[38;5;241m=\u001b[39m mu\n",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m, in \u001b[0;36mload_returns_and_price\u001b[1;34m(ticker)\u001b[0m\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_index()\n\u001b[0;32m      6\u001b[0m s \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39masfreq(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mffill()\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m----> 7\u001b[0m p0 \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m s, \u001b[38;5;28mfloat\u001b[39m(p0)\n",
      "File \u001b[1;32mc:\\Users\\lowsl\\New folder\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\lowsl\\New folder\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Close'"
     ]
    }
   ],
   "source": [
    "tickers = list_tickers()\n",
    "mean_paths = {}   # {ticker: Series length H}\n",
    "last_close = {}   # {ticker: float}\n",
    "\n",
    "for t in tqdm(tickers, desc=\"Forecasting\", ncols=80):\n",
    "    r, p0 = load_returns_and_price(t)\n",
    "    mu = arima_mean_path(r, H)\n",
    "    mean_paths[t] = mu\n",
    "    last_close[t] = p0\n",
    "\n",
    "# Assemble into tidy DataFrames\n",
    "mean_df = pd.DataFrame(mean_paths).T         # (ticker x date_index)\n",
    "# Give simple column names T+1..T+H for convenience\n",
    "mean_df.columns = [f\"T+{i+1}\" for i in range(mean_df.shape[1])]\n",
    "last_close_s = pd.Series(last_close).rename(\"LastClose\")\n",
    "universe = mean_df.index.tolist()\n",
    "\n",
    "print(f\"Tickers: {len(universe)}; Horizon: {H}\")\n",
    "mean_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bfe60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_path = f\"{ART}/mean_returns_10d.parquet\"\n",
    "last_close_path = f\"{ART}/last_close.parquet\"\n",
    "diag_path = f\"{ART}/diag.json\"\n",
    "\n",
    "mean_df.to_parquet(mean_path)     # (ticker x H) daily return forecasts\n",
    "last_close_s.to_parquet(last_close_path)\n",
    "\n",
    "with open(diag_path, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"horizon\": H,\n",
    "        \"method\": \"ARIMA(1,0,1) on daily returns\",\n",
    "        \"universe\": universe\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"  -\", mean_path)\n",
    "print(\"  -\", last_close_path)\n",
    "print(\"  -\", diag_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df56096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample = universe[0]\n",
    "mu = mean_df.loc[sample]\n",
    "plt.figure()\n",
    "mu.T.plot(marker=\"o\")\n",
    "plt.title(f\"{sample} — 10-Day Return Forecast (ARIMA 1,0,1)\")\n",
    "plt.ylabel(\"Daily expected return\")\n",
    "plt.xlabel(\"Horizon (T+)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206791c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(26, 6))\\ndata[\\'Adj Close\\'].plot(x = 250, y = 10, linewidth = 0.8)\\nplt.show()\\n\\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\\nacf_original = plot_acf(data[\\'Adj Close\\'])\\npacf_original = plot_pacf(data[\\'Adj Close\\'])\\n\\n# adf test\\nfrom statsmodels.tsa.stattools import adfuller\\nadf_result = adfuller(data[\\'Adj Close\\'])\\nprint(\"ADF Statistic:\", adf_result[1])\\n# fails to reject null hypothesis at 5% sig level, non-stationary\\n\\ntransforming to stationary (stabilise mean)\\ndf_train_diff = data[\\'Adj Close\\'].diff().dropna()\\ndf_train_diff.plot()\\n\\nacf_diff = plot_acf(df_train_diff)\\npacf_diff = plot_pacf(df_train_diff)\\n\\nadf_result_diff = adfuller(df_train_diff)\\nprint(\"ADF Statistic (differenced):\", adf_result_diff[1])\\n# reject null hypothesis at a 5% significance level, stationary\\n\\n# make time series predictions\\n\\nimport matplotlib.pyplot as plt\\nresiduals = model_fit.resid[1:]\\nfig, ax = plt.subplots(1,2)\\nresiduals.plot(title = \"Residuals\", ax = ax[0])\\nresiduals.plot(kind = \\'kde\\', title = \"Density\", ax = ax[1])\\nplt.show()\\n\\n\\nplot_acf(residuals)\\nplot_pacf(residuals)\\nplt.show()\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plt.figure(figsize=(26, 6))\n",
    "data['Adj Close'].plot(x = 250, y = 10, linewidth = 0.8)\n",
    "plt.show()\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "acf_original = plot_acf(data['Adj Close'])\n",
    "pacf_original = plot_pacf(data['Adj Close'])\n",
    "\n",
    "# adf test\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "adf_result = adfuller(data['Adj Close'])\n",
    "print(\"ADF Statistic:\", adf_result[1])\n",
    "# fails to reject null hypothesis at 5% sig level, non-stationary\n",
    "\n",
    "transforming to stationary (stabilise mean)\n",
    "df_train_diff = data['Adj Close'].diff().dropna()\n",
    "df_train_diff.plot()\n",
    "\n",
    "acf_diff = plot_acf(df_train_diff)\n",
    "pacf_diff = plot_pacf(df_train_diff)\n",
    "\n",
    "adf_result_diff = adfuller(df_train_diff)\n",
    "print(\"ADF Statistic (differenced):\", adf_result_diff[1])\n",
    "# reject null hypothesis at a 5% significance level, stationary\n",
    "\n",
    "# make time series predictions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "residuals = model_fit.resid[1:]\n",
    "fig, ax = plt.subplots(1,2)\n",
    "residuals.plot(title = \"Residuals\", ax = ax[0])\n",
    "residuals.plot(kind = 'kde', title = \"Density\", ax = ax[1])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot_acf(residuals)\n",
    "plot_pacf(residuals)\n",
    "plt.show()\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
